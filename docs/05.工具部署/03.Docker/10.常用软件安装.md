---
title: 常用软件安装
date: 2022-06-06 14:39:00
permalink: /Docker/softwareInstall
categories:
  - 工具部署
  - Docker
tags:
  - Docker
---

## 安装Tomcat

拉取9.0.63

```sh
docker pull tomcat:9.0.63-jdk8-openjdk-slim
```

启动容器

```sh
[root@localhost ~]# docker run -d -p 8080:8080 --name tomcat9 tomcat:9.0.63-jdk8-openjdk-slim 
aa1bff62aa568887cd8611c4922a1ba8cd415c221cd7577af7c5ba3dce0e6935
```

进入容器 把webapp.dist中的文件复制到webapp中

```sh
[root@localhost ~]# docker exec -it aa1bff62aa568887cd8611c4922a1ba8cd415c221cd7577af7c5ba3dce0e6935 /bin/bash
root@aa1bff62aa56:/usr/local/tomcat# ls
BUILDING.txt     LICENSE  README.md      RUNNING.txt  conf  logs            temp     webapps.dist
CONTRIBUTING.md  NOTICE   RELEASE-NOTES  bin          lib   native-jni-lib  webapps  work
root@aa1bff62aa56:/usr/local/tomcat# cp -r webapps.dist/* webapps
root@aa1bff62aa56:/usr/local/tomcat# cd webapps
root@aa1bff62aa56:/usr/local/tomcat/webapps# ls
ROOT  docs  examples  host-manager  manager
```

再访问，就不是404了



## 安装MySQL

### 简单版

拉取

```sh
docker pull mysql:8.0.25
```

启动

```sh
[root@localhost ~]# docker run -p 33066:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:8.0.25 
6fa14e9ba3b17e0507d911636e76093c2c5c03ad62f163b9886a5b3315176379
```

![image-20220606151606202](https://images.zaiolos.top/images/image-20220606151606202.png)

进入容器

```sh
[root@localhost ~]# docker exec -it 6fa14e9ba3b1 /bin/bash
```

连接上mysql

```sh
mysql -u root -p 输入上面的密码
```

成功进入

![image-20220606151752901](https://images.zaiolos.top/images/image-20220606151752901.png)

建数据库建表测试

```sh
mysql> create database test;
Query OK, 1 row affected (0.00 sec)
mysql> use test
Database changed
mysql> create table test(id int,name varchar(20));
Query OK, 0 rows affected (0.03 sec)

mysql> insert into test values(1,'test');
Query OK, 1 row affected (0.01 sec)

mysql> select * from test;
+------+------+
| id   | name |
+------+------+
|    1 | test |
+------+------+
1 row in set (0.00 sec)
```



### 挂载数据卷版

运行容器并挂载数据卷

```sh
docker run -d -p 33066:3306 --privileged=true -v /zdkuse/mysql/log:/var/log/mysql -v /zdkuse/mysql/data:/var/lib/mysql -v /zdkuse/mysql/conf:/etc/mysql.conf.d -e MYSQL_ROOT_PASSWORD=root --name newmysql mysql:8.0.25
```



新建my.cnf文件

```sh
cd /zdkuse/mysql/conf
vim my.cnf
```

```
[client]
default_character_set=utf8mb4
[mysqld]
collation_server = utf8mb4_general_ci
character_set_server = utf8mb4
```



## 安装Redis

拉镜像

```sh
docker pull redis:6.0.8
```

将一个模板redis.conf拷贝到数据卷本机目录下

```sh
文件为 /zdkuse/redis/redis.conf
```

修改内容

> requirepass 密码
>
> 注释掉 # bind 127.0.0.1
>
> 将daemonize yes注释起来或者 daemonize no设置，因为该配置和docker run中-d参数冲突，会导致容器一直启动失败
>
> 开启redis数据持久化 appendonly yes 可选



运行

```sh
docker run -p 6378:6379 --name myredis --privileged=true -v /zdkuse/redis/redis.conf:/etc/redis/redis.conf -v /zdkuse/redis/data:/data -d redis:6.0.8 redis-server /etc/redis/redis.conf
```

注意，这里有大坑，redis.conf这个文件，不能有空行的" "空格，否则运行报错

[正确文件链接](https://cloud.zaiolos.top/s/XjTO)



## 部署Redis集群

> 1~2亿条数据需要缓存，请问如何设计这个存储案例
>
> 使用分布式存储

### 分布式存储-哈希取余算法

![image-20220607155226668](https://images.zaiolos.top/images/image-20220607155226668.png)

> 2亿条记录就是2亿个k,v，我们单机不行必须要分布式多机，假设有3台机器构成一个集群，用户每次读写操作都是根据公式：
>
> hash(key) % N个机器台数，计算出哈希值，用来决定数据映射到哪一个节点上。

优点：

> 简单粗暴，直接有效，只需要预估好数据规划好节点，例如3台、8台、10台，就能保证一段时间的数据支撑。使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡+分而治之的作用。

缺点：

> 原来规划好的节点，进行扩容或者缩容就比较麻烦了，不管扩缩，每次数据变动导致节点有变动，映射关系需要重新进行计算，在服务器个数固定不变时没有问题，如果需要弹性扩容或故障停机的情况下，原来的取模公式就会发生变化：Hash(key)/3会变成Hash(key) /?。此时地址经过取余运算的结果将发生很大变化，根据公式获取的服务器也会变得不可控。某个redis机器宕机了，由于台数数量变化，会导致hash取余全部数据重新洗牌。



### 一致性哈希算法

> 提出一致性Hash解决方案。 目的是当服务器个数发生变动时， 尽量减少影响客户端到服务器的映射关系



### 部署3主3从：

运行启动

```sh
docker run -d --name redis-node-1 --net host --privileged=true -v /data/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381

docker run -d --name redis-node-2 --net host --privileged=true -v /data/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382

docker run -d --name redis-node-3 --net host --privileged=true -v /data/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383

docker run -d --name redis-node-4 --net host --privileged=true -v /data/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384

docker run -d --name redis-node-5 --net host --privileged=true -v /data/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385

docker run -d --name redis-node-6 --net host --privileged=true -v /data/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386
```

```sh
[root@localhost /]# docker ps
CONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS     NAMES
8b737aeb68ce   redis:6.0.8   "docker-entrypoint.s…"   6 seconds ago    Up 5 seconds              redis-node-6
36a789dcc763   redis:6.0.8   "docker-entrypoint.s…"   10 seconds ago   Up 9 seconds              redis-node-5
3fddc5bb53cb   redis:6.0.8   "docker-entrypoint.s…"   13 seconds ago   Up 13 seconds             redis-node-4
20c8f7d45f12   redis:6.0.8   "docker-entrypoint.s…"   17 seconds ago   Up 17 seconds             redis-node-3
7b926dc255f3   redis:6.0.8   "docker-entrypoint.s…"   24 seconds ago   Up 23 seconds             redis-node-2
1908bc53858d   redis:6.0.8   "docker-entrypoint.s…"   28 seconds ago   Up 27 seconds             redis-node-1
```



#### 构建主从关系

进入node1

```sh
docker exec -it redis-node-1 /bin/bash
```

构建关系(ip是宿主机ip)

```sh
redis-cli --cluster create 211.69.238.105:6381 211.69.238.105:6382 211.69.238.105:6383 211.69.238.105:6384 211.69.238.105:6385 211.69.238.105:6386 --cluster-replicas 1
```

> --cluster-replicas 1 表示为每个master创建一个slave节点

出现以下算是成功

```sh
[root@localhost /]# docker exec -it redis-node-1 /bin/bash
root@localhost:/data# redis-cli --cluster create 211.69.238.105:6381 211.69.238.105:6382 211.69.238.105:6383 211.69.238.105:6384 211.69.238.105:6385 211.69.238.105:6386 --cluster-replicas 1
>>> Performing hash slots allocation on 6 nodes...
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 211.69.238.105:6385 to 211.69.238.105:6381
Adding replica 211.69.238.105:6386 to 211.69.238.105:6382
Adding replica 211.69.238.105:6384 to 211.69.238.105:6383
>>> Trying to optimize slaves allocation for anti-affinity
[WARNING] Some slaves are in the same host as their master
M: 14492903ed96cef3d9e58b52d5affd27ba88edf0 211.69.238.105:6381
   slots:[0-5460] (5461 slots) master
M: 99b74bdf77893a6353e4f852de3b35e2550e93ed 211.69.238.105:6382
   slots:[5461-10922] (5462 slots) master
M: ec222c92f9ba2d11e1be3726981a9a66327cb13a 211.69.238.105:6383
   slots:[10923-16383] (5461 slots) master
S: 5ff81b524030e5a58aa53802aa35f6e43e7eef6c 211.69.238.105:6384
   replicates 99b74bdf77893a6353e4f852de3b35e2550e93ed
S: d62be6d855c50b9c3bb2216230382e4e2b594622 211.69.238.105:6385
   replicates ec222c92f9ba2d11e1be3726981a9a66327cb13a
S: ea4b2fd2676945eba8a283b75e9ba6c58043d75b 211.69.238.105:6386
   replicates 14492903ed96cef3d9e58b52d5affd27ba88edf0
Can I set the above configuration? (type 'yes' to accept): yes
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join
.
>>> Performing Cluster Check (using node 211.69.238.105:6381)
M: 14492903ed96cef3d9e58b52d5affd27ba88edf0 211.69.238.105:6381
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: ea4b2fd2676945eba8a283b75e9ba6c58043d75b 211.69.238.105:6386
   slots: (0 slots) slave
   replicates 14492903ed96cef3d9e58b52d5affd27ba88edf0
S: d62be6d855c50b9c3bb2216230382e4e2b594622 211.69.238.105:6385
   slots: (0 slots) slave
   replicates ec222c92f9ba2d11e1be3726981a9a66327cb13a
M: ec222c92f9ba2d11e1be3726981a9a66327cb13a 211.69.238.105:6383
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 5ff81b524030e5a58aa53802aa35f6e43e7eef6c 211.69.238.105:6384
   slots: (0 slots) slave
   replicates 99b74bdf77893a6353e4f852de3b35e2550e93ed
M: 99b74bdf77893a6353e4f852de3b35e2550e93ed 211.69.238.105:6382
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```



通过6381这个结点查看集群信息：

```sh
redis-cli -p 6381
cluster info
```

```sh
root@localhost:/data# redis-cli -p 6381
127.0.0.1:6381> cluster info
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1
cluster_stats_messages_ping_sent:264
cluster_stats_messages_pong_sent:263
cluster_stats_messages_sent:527
cluster_stats_messages_ping_received:258
cluster_stats_messages_pong_received:264
cluster_stats_messages_meet_received:5
cluster_stats_messages_received:527
```

> 可以看到总结点个数以及从机的数量



通过下面的命令，查看具体的主、从机分别是哪个服务

```sh
cluster nodes
```

```sh
127.0.0.1:6381> cluster nodes
ea4b2fd2676945eba8a283b75e9ba6c58043d75b 211.69.238.105:6386@16386 slave 14492903ed96cef3d9e58b52d5affd27ba88edf0 0 1654606867000
d62be6d855c50b9c3bb2216230382e4e2b594622 211.69.238.105:6385@16385 slave ec222c92f9ba2d11e1be3726981a9a66327cb13a 0 1654606867000
ec222c92f9ba2d11e1be3726981a9a66327cb13a 211.69.238.105:6383@16383 master - 0 1654606867662 3 connected 10923-16383
5ff81b524030e5a58aa53802aa35f6e43e7eef6c 211.69.238.105:6384@16384 slave 99b74bdf77893a6353e4f852de3b35e2550e93ed 0 1654606868688
99b74bdf77893a6353e4f852de3b35e2550e93ed 211.69.238.105:6382@16382 master - 0 1654606869708 2 connected 5461-10922
14492903ed96cef3d9e58b52d5affd27ba88edf0 211.69.238.105:6381@16381 myself,master - 0 1654606868000 1 connected 0-5460
```

> slave 后面跟的id就是这个机器的master的id
>
> 它们的关系是：
>
> - 6381(m)->6386(c)
> - 6382(m)->6384(c)
> - 6383(m)->6385(c)
>
> 这个主从关系是随机分配的，并不是指定顺序的

