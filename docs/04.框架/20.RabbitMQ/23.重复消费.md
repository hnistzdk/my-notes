---
title: 重复消费
date: 2022-09-16 20:19:13
permalink: /pages/53a201/
categories:
  - 框架
  - RabbitMQ
tags:
  - 
---
<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [消息重复的场景](#%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D%E7%9A%84%E5%9C%BA%E6%99%AF)
  - [发送消息时重复](#%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E6%97%B6%E9%87%8D%E5%A4%8D)
  - [投递时消息重复](#%E6%8A%95%E9%80%92%E6%97%B6%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D)
  - [负载均衡时消息重复](#%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%97%B6%E6%B6%88%E6%81%AF%E9%87%8D%E5%A4%8D)
- [解决方案](#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88)
  - [利用幂等性](#%E5%88%A9%E7%94%A8%E5%B9%82%E7%AD%89%E6%80%A7)
    - [1. 数据库唯一索引](#1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95)
    - [2. 设置前置条件](#2-%E8%AE%BE%E7%BD%AE%E5%89%8D%E7%BD%AE%E6%9D%A1%E4%BB%B6)
    - [3. 通过全局ID实现](#3-%E9%80%9A%E8%BF%87%E5%85%A8%E5%B1%80id%E5%AE%9E%E7%8E%B0)
    - [4. 使用业务唯一标识key](#4-%E4%BD%BF%E7%94%A8%E4%B8%9A%E5%8A%A1%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86key)
      - [生产者设置唯一标识的key值](#%E7%94%9F%E4%BA%A7%E8%80%85%E8%AE%BE%E7%BD%AE%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%9A%84key%E5%80%BC)
      - [消费者识别key相同的重复消息](#%E6%B6%88%E8%B4%B9%E8%80%85%E8%AF%86%E5%88%ABkey%E7%9B%B8%E5%90%8C%E7%9A%84%E9%87%8D%E5%A4%8D%E6%B6%88%E6%81%AF)
    - [5. 使用分布式锁](#5-%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81)
      - [生产者端传递业务id](#%E7%94%9F%E4%BA%A7%E8%80%85%E7%AB%AF%E4%BC%A0%E9%80%92%E4%B8%9A%E5%8A%A1id)
      - [消费者端进行业务逻辑判断](#%E6%B6%88%E8%B4%B9%E8%80%85%E7%AB%AF%E8%BF%9B%E8%A1%8C%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91%E5%88%A4%E6%96%AD)
      - [为什么redis-cluster在极端情况下不适合做分布式锁](#%E4%B8%BA%E4%BB%80%E4%B9%88redis-cluster%E5%9C%A8%E6%9E%81%E7%AB%AF%E6%83%85%E5%86%B5%E4%B8%8B%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9A%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

---
title: 重复消费
date: 2022-09-16 20:19:13
permalink: /pages/7f63a0/
categories:
  - 消息队列
tags:
  - 消息队列
---
## 消息重复的场景
### 发送消息时重复
::: tip
当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对生产者的确认应答失败。此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。
:::

### 投递时消息重复
::: tip
消息消费的场景下，消息已投递到消费者并完成业务处理，当消费者给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。
:::

### 负载均衡时消息重复
::: tip
包括但不限于网络抖动、Broker 重启以及消费者应用重启。当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。
:::

## 解决方案
### 利用幂等性
::: tip
既然在生产和消费过程中都有可能出现重复消费问题，那我们从消费的末端去处理，把识别出重复的消息，然后抛弃此消息，那不就能避免重复消息对业务的影响，这也就是幂等处理。

<br />所谓幂等性，就是数据无论操作多少次，所产生的影响跟执行一次是一样的，比如对于读操作来说，无论读取多少次数据，都跟读取一次的数据是一样的，所以读操作是一个幂等性操作，而添加操作，添加多次会有多条记录，因而写操作则是非幂等性操作。因而对于以上场景，只要保证消息消费的幂等性，就能解决重复消费的问题。
:::

#### 1. 数据库唯一索引
> 可以通过给消息的某一些属性设置唯一约束，比如增加唯一uuid，添加的时候查询是否存对应的uuid，存在不操作，不存在则添加，那样对于相同的uuid只会存在一条数据。其实，只要类似“insert if not exist”的操作都可能，但需要保证查询跟添加的操作必须是原子性操作。例如：上面取款发短信的场景则可以借助redis的setnx实现。

```java
public class SendServiceImpl implements SendService {

    @Autowired
    private JedisClient jedisClient;
    @Value("channel")
    private String channel;

    @Override
    public boolean sendMessage(Message message) {
        String uuid = message.getUuid();
        // 判断是否已经发送了
        boolean send = jedisClient.setnx(channel, uuid) == 1;
        if(send){
            // TODO 开始发送短信
        }
        return true;
    }
}
```
#### 2. 设置前置条件
> 在更新的时候，可以通过设置一定的前置条件来保证数据幂等，比如给用户发送短信是非幂等操作，但可以添加前置条件，变成如果该用户未发送过短信，则给用户发送短信，此时的操作则是幂等性操作。但在实际上，对于一个问题如何获取前置条件往往比较复杂，此时可以通过设置版本号version，没修改一次则版本号+1，在更新时则通过判断两个数据的版本号是否一致。

```sql
UPDATE message SET m_status = #{status} WHERE uuid = #{uuid} AND version = #{version}
```
#### 3. 通过全局ID实现
> 最后的方式就比较暴力也比较通用，通过设置全局Id去实现。实现的思路是，在发送消息时，给每条消息指定一个全局唯一的 ID（可以通过雪花算法去实现），消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据。
>
> <br />虽然看起来好像不复杂，单机环境实现也比较简单，就是查询更新的思路，但在分布式环境上一点也不简单，因为必须保证查询跟更新是原子性的操作，不能查询完又有另外一个事务去更新了数据。当然，对于这种问题也可以通过分布式事务和分布式锁去实现，但与之的也降低了系统的性能。

#### 4. 使用业务唯一标识key
##### 生产者设置唯一标识的key值
::: tip
既然后要能识别重复消息，那必须是此条消息有唯一的标识。到了这里，你肯定会想到用RocketMQ生成的MessageId不就可以了吗？但这不是最佳方法，因为 MessageId有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以MessageId作为处理依据。而最好的方式是以业务唯一标识作为幂等处理的关键依据（如订单ID）。

<br />业务的唯一标识可以在生产者通过消息 Key 设置。实现代码如下：
:::

```java
Message message = new Message();
message.setKey("ORDERID_001");
SendResult sendResult = producer.send(message);
```
##### 消费者识别key相同的重复消息
::: tip
消费者收到消息时可以根据消息的 Key判断是否重复来实现消息幂等。这里我们用到了redis存放消息key值（因为redis读取快），并且对于key值大存放时长可以设置，超过了时长就会被清除掉
:::
```java
consumer.subscribe("ons_test", "*", new MessageListener() {
    public Action consume(Message message, ConsumeContext context) {
        String key = message.getKey()
        // 根据业务唯一标识的 Key 做幂等处理
    }
});
```
> 这里可以先判断key是否在redis中存在，如果存在则抛弃不走下面的业务逻辑；如果，在redis中没有查到，则继续下面的业务逻辑处理

#### 5. 使用分布式锁
![2331630-20210722075625778-244580759](https://images.zaiolos.top/images/202209162027755.png)
##### 生产者端传递业务id
```java
@Test
public void testSendMessage(){
    //业务id
    String id = UUID.randomUUID().toString();
    //封装了业务id的消息元数据
    CorrelationData correlationData = new CorrelationData(id);
    //发送消息，并且携带消息的业务id
    rabbitTemplate.convertAndSend("my_boot_topic_exchange",
            "product.add",
            "hello message",
            correlationData
            );
}
```
##### 消费者端进行业务逻辑判断
```java
/**
 * 消费端的幂等性的实现
 */
@RabbitListener(queues = "my_boot_topic_queue")
public void processByMSG(Message message,Channel channel) throws IOException {
    //如何获得消息的业务id
   String messageId = message.getMessageProperties().getHeader("spring_returned_message_correlation");	//设置分布式锁
    Boolean lock = redisTemplate.opsForValue().setIfAbsent(messageId, 1,100000, TimeUnit.MILLISECONDS);
    if(lock){
        //做消费
        System.out.println("添加用户成功");
        //手动ack
        channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
    }else{
        //不做消费
        System.out.println("已重复消费");
        channel.basicReject(message.getMessageProperties().getDeliveryTag(),false);
    }
}
```
##### 为什么redis-cluster在极端情况下不适合做分布式锁
![](https://images.zaiolos.top/images/202209162025244.png)
