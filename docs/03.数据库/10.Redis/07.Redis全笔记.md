---
title: Redis 全笔记
date: 2022-01-06 10:48:17
permalink: /redis/7
categories: 
  - 数据库
  - Redis
tags: 
  - Redis
---
## Redis记录

### 概述

1. Redis是noSQL(not only SQL)数据库 即非关系型数据库
2. 以key-value形式缓存数据在内存中，读取速度极快支持多种数据结构如string,list,set,zset,hash等
3. 这些数据都支持push/pop,add/remove以及取交集并集差集等操作，且这些操作都是原子性的也可进行数据持久化，
4. 将数据存储到硬盘：RDB和AOF方式
5. Redis与memcached区别：Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件,在此基础上，Redis实现了主从同步

### 安装Redis

- 先给Linux安装gcc环境 yum -y install gcc automake autoconf libtool make 

- 将gcc升级到9

  ```shell
  # gcc -v                             # 查看gcc版本
  # yum -y install centos-release-scl  # 升级到9.1版本
  # yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils
  # scl enable devtoolset-9 bash
  ```

  

- 在/目录下新建soft文件夹，将redis的tar.gz包放入，使用tar -zxvf redis-xx解压(如果没安装tar，可以使用 yum install tar -y安装)

- 在redis的解压目录下输入make指令

- 在redis的解压目录下输入 make install PREFIX=/usr/local/redis(prefix表示安装的目录，不指定的话默认安装到/usr/local/bin里面)

- 观察/usr/local/redis中的文件结构，需要安装tree命令软件(yum install tree -y)

- 然后启动redis服务：/usr/local/redis/bin/redis-server

- 再打开一个终端窗口使用redis客户端操作：/usr/local/redis/bin/redis-cli

- 在redis服务启动的窗口使用ctrl+c或shutdown(推荐)或使用kill -9 进程id杀死redis进程。shutdown命令后的参数可以是save/nosave，一般用save进行本地保存以便下次启动时恢复数据

- 通过ps -aux|grep redis可查看redis服务端的进程

- firewall-cmd --zone=public --add-port=6379/tcp --permanent：开启6379防火墙

- firewall-cmd --reload：重新加载防火墙



### Redis配置允许远程访问

1. 配置redis访问密码

   ```bash
   port 6500
   daemonize yes
   pidfile /var/run/redis_6500.pid
    logfile "/usr/local/redis/bin/redis-6500.log"
   dbfilename dump-6500.rdb
    requirepass 123456
   ```

2. 指定监听的ip地址

   ```bash
   port 6500
   daemonize yes
   pidfile /var/run/redis_6500.pid
    logfile "/usr/local/redis/bin/redis-6500.log"
   dbfilename dump-6500.rdb
    bind 192.168.3.42
   ```

3. 直接禁用保护模式(不推荐、危险)

   ```bash
   port 6500
   daemonize yes
   pidfile /var/run/redis_6500.pid
    logfile "/usr/local/redis/bin/redis-6500.log"
   dbfilename dump-6500.rdb
    protected-mode no
   ```

4. 推荐使用设置密码+设置监听IP的方式

   ```bash
   port 6500
   daemonize yes
   pidfile /var/run/redis_6500.pid
   logfile "/usr/local/redis/bin/redis-6500.log"
    dbfilename dump-6500.rdb
   bind 192.168.3.42
    requirepass 123456
   ```



### 其他的Redis配置

```bash
1. loglevel：redis的日志记录等级，默认为notice，共有四级(debug<verbose<notice<warning)

2. databases：redis服务中数据库的数量，通过select+数字切换，默认为0

3. timeout：超时关闭连接的时间，当连接redis服务的客户端timeout秒没有活动的时候就关闭这个连接。若设置为0则表示永远不关闭

4. save：指出在多长时间内，有多少次更新操作，就将数据同步到数据文件

5.  rdbcompression：指定存储至本地数据库时是否压缩数据，默认为 yes

   Redis 采用 LZF 压缩，如果为了节省 CPU 时间，可以关闭该选项，但会导致数据库文件变的巨大 
   
6.  dir： 本地数据库存放路径，默认值为 ./ 

7.  slaveof： 当本机为从服务时，设置主服务的IP及端口，如：192.168.0.100:6500 

8.  slave-read-only： 当本机为从服务时，是否设置为只读状态 

9.  masterauth： 当本机为从服务时，设置主服务的连接密码，如：123456 

10.  maxclients： 最大客户端连接数，默认10000，参照`/soft/redis-6.0.6/redis.conf`中的说明。可在客户端中使用config get maxclients查看这个配置

```

11. appendonly：指定是否在每次更新操作后进行日志记录（注意是进行日志记录，而不是存储数据），默认为no。Redis 在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis 本身同步数据文件是按上面 save 条件来同步的，所以有的数据会在一段时间内只存在于内存中

12. appendfilename：指定更新日志文件名，默认为 appendonly.aof，默认的就是appendonly.aof文件

  ```
  
  ###启动redis

  ```bash
/usr/local/redis/bin/redis.conf或/usr/local/redis/bin/redis-server
  ```

  #### 连接客户端

```bash
  #-h：指定ip	-p：指定端口	  -a：若开启了验证，需指定验证密码登录
/usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 -a 123
```

  

  #### 设置redis开机启动

  ```bash
  1：编辑 /etc下的 rc.local 文件,将redis的启动命令写入文件
  vim /etc/rc.local
  
  2：编辑脚本内容
  /usr/local/redis/redis-server /usr/local/redis/redis.conf
  
tip：若开机脚本不起作用，可能因为 rc.local 的执行权限问题。
  chmod 755 /etc/rc.local 

  ```

  

  

  #### 用途举例

  - 获取最新的N个数据：通过list实现按自然时间排序的数据
  - 排行榜topN：利用zset(有序集合)实现
  - 时效性数据，如手机、邮箱验证码：利用Expire过期
  - 计数器，秒杀：原子性，利用自增方法INCR、DECR
  - 去除大量数据中的重复数据：利用Set集合
  - 构建队列：利用list
  - 发布订阅消息系统：pub/sub模式

### Redis键(key)

- **keys *：查看当前库中所有key (匹配：keys *1)**
- **exists key：判断某个key是否存在**
- **type key：查看你的key是什么类型**
- **del key：删除指定的key的数据**
- **unlink key：非阻塞删除数据(异步删除,不是立刻删除)，仅将key从keyspace元数据中删除，真正的删除会在后续异步执行**
- **expire key 10(单位是seconds)：为给定的key设置过期时间**
- **ttl key：查看还有多少秒过期，-1表示永不过期，-2表示已经过期**
- **select (数字)：切换数据库(0-15)一共16个数据库**
- **dbsize：查看当前数据库的key的数量**
- **flushdb：清空当前库**
- **flushall：清空所有库**



### String

```bash
String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。v
String类型是二进制安全的。意味着Redis的string 可以包含任何数据。比如jpg图片或者序列化的对象。·
String类型是Redis最基本的数据类型，一个Redis 中字符串value最多可以是512M
```

### 原子性

```bash
所谓原子操作是指不会被线程调度机制打断的操作;
这种操作一旦开始，就会一直运行到结束，中间不会有任何context switch(切换到另一线程)
(1)在单线程中，能够在单条指令中完成的操作都可以认为是"原子操作"，因为中断只能发生在指令之间
(2)在多线程中，不能被其他进程(线程)打断的操作就叫原子操作，redis单命令的原子性主要得益于redis是单线程
```





#### 基本命令

- set [key] [value] 存一个，重复set同一个key ，原来的值会被覆盖
- get [key] 获取对应key 的值
- append [key] [value] 在指定key 的值后面追加value字符串
- strlen [key] 获取对应key值的字符串长度
- setnx [key] [value]：只有在key不存在时设置key的值
- incr [key] 将key中储存的数字值加1，只能对数字值操作，如果为空，新增这个key，赋值为1
- decr [key] 将key中储存的数字值减1，只能对数字值操作，如果为空，新增这个key，赋值为-1
- incrby/decrby [key] [步长]：将key中储存的数字进行增减自定义步长
- mset [key] [value] [key] [value] [key] [value]....同时设置一个或多个key value键值对
- mget [key] [value] [key] [value] [key] [value]....同时获取一个或多个key的值
- msetnx [key] [value] [key] [value]：当其中有一个key是已存在的，整个msetnx操作会失败(原子性的)
- getrange [key] [index] [end] 获取值得范围，类似Java substring，左右均为闭区间
- setrange [key] [index] [value] 用value覆盖从index(包含index)开始后的字符串value长度个字符串(index从0开始)
- setex [key] [过期时间] [value]：在设置值的时候即可设置过期时间
- getset [key] [value]：以新换旧，设置新值得到旧值(取到的是旧值，然后存储的旧值被新值替换)



#### String的数据结构

```bash
String 的string的底层数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。
```



### List

#### 概述

```bash
单键多值

Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部(左边）或者尾部(右边)。
它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。

```



#### 常用命令

- lrange/rrange [key] [start] [stop] 按照索引下标获取元素(从左到右或从右到左)

  如果start是0，stop是-1，即可取到所有值，因为0表示左边第一个，-1表示右边第一个

- lpush/rpush [key] [value] [key] [value] [key] [value]..... ：从左或右插入一个或多个值，插入方式为左插法或右插法，即每次插入到当前方向的最后一个的后面。

  例如lpush k1 v1 k2 v2 k3 v3，然后使用lrange 0 2取到的值得顺序是v3 v2 v1，因为插入的方式是先v1

  ，然后v2 v1，然后v3 v2 v1。

- lpop/rpop [key] 从左边/右边吐出一个值

- rpoplpush [key1] [key2] 从[key1]列表右边吐出一个值，插到[key2]列表的左边

- lindex[key] [index] 根据索引获取元素(从左到右)

- llen[key] 获得链表长度

- linsert[key] before/after [value] [newvalue] 在value的之前或之后插入newvalue

- lset[key] [index] [value] 将列表key下标为index的值替换为value

- lrem[key] [n] [value] 从左边开始删除n个value

#### List的数据结构

```bash
List的数据结构为快速链表quickList。

首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表。
它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成quicklist。

因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。

Redis将链表和ziplist结合起来组成了quicklist。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。
```





### Set

#### 概述

```bash
Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择。

并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。

Redis的set是string类型的无序集合。它底层其实是一个value为null的hash表，所以添加，删除，查找的复杂度都是O(1)。

一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变

```





#### 常用命令

- sadd[key] [value1] [value2] 将一个或多个元素加入到集合key中

- smembers[key] 取出该集合的所有值
- sismember[key] [value] 判断集合key是含有该value，有为1，没有为0
- scard[key] 返回该集合的元素个数
- srem[key] [value1] [value2]..删除集合中的某(几)个元素
- spop[key] [n]随机从该集合中吐出n个值，不加n默认吐出一个，即拿出，会从集合中删除
- srandmember[key] [n]随机从该集合中取出n个值，不会从集合中删除
- smove[source] [destination] value 把集合source中的值为value的元素移动到集合destination中
- sinter[key1] [key2] 返回两个集合的交集元素
- sunion[key1] [key2] 返回两个集合的并集元素
- sdiff[key1] [key2] 返回两个集合的差集元素(key1中有的，key2中没有的)



#### set的数据结构

```bash
set的数据结构是dict(dictionary)字典，字典是用哈希表实现的

Java中 HashSet的内部实现使用的是 HashMap，只不过所有的value都指向同一个对象。

Redis的set结构也是一样，它的内部也使用hash结构，所有的value都指向同一个内部值。
```



### 有序集合zset

#### 概述

```bash
Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。·
不同之处是有序集合的每个成员都关联了一个评分(score),这个评分(score)被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了。
因为元素是有序的，所以你也可以很快的根据评分(score)或者次序(position)来获取一个范围的元素。
访问有序集合的中间元素也是非常快的,因此你能够使用有序集合作为一个没有重复成员的智能列表。
```



#### 常用命令

- zadd[key] [score1] [value1] [score2] [value2]...：将一个或多个member元素及其score值加入到有序集合key中

- zrange[key] [start] [stop] [WAHTSCORES]：返回有序结合中，下标在start和top之间的元素,带WAHTSCORES可以让score和值一起返回。stop为-1时返回所有数据

- zrangebyscore key minmax[withscores] [limit offset count]：返回有序集合key中，所有score值介于min和max之间(包括等于min和max)的成员。有序集合按score值递增排序(从小到大)

- zrevrangebyscore key maxmin[withscores] [limit offset count]：同上，排序方式改为从大到小
- zincrby[key] [increment] [value] 为元素的score加上增量
- zrem[key] [value]删除该集合下，指定值的元素
- zcount[key] [min] [max]统计该集合的元素score在区间[min,max]之间的元素个数
- zrank[key] [value] 返回该值在集合中的排名，从0开始

案例：如何利用zset实现一个文章访问量的排行榜

#### 数据结构

```bash
SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map<String，Double>，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。
zset底层使用了两个数据结构
(1) hash ,hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。
(2）跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。
```



#### 跳跃表

![image-20211101133155477](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133155477.png)	

### hash

key item value

命令：

-  hdel key field1 [field2] 删除一个或多个哈希表字段 
- hexists key field  查看哈希表 key 中，指定的字段是否存在。 
- hget key field  获取存储在哈希表中指定字段的值。 
- hgetall key  获取在哈希表中指定 key 的所有字段和值 
- hincrby key field increment 为哈希表key中的指定字段的整数值加上常量increment
- hincrbyfloat key field increment  为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 
- hkeys key 获取哈希表中所有字段
- hlen key 获取哈希表中字段的数量
- hmget key field1 [field2] 获取所有给定字段的值
- hmset key field1 value [field2 value2]  同时将多个 field-value (域-值)对设置到哈希表 key 中。 
- hset key field value 将哈希表 key 中的字段 field 的值设为 value 
- hsetnx key field value  只有在字段 field 不存在时，设置哈希表字段的值。 
- hvals key 获取哈希表中所有值
- hscan key cursor [MATCH pattern] [COUNT count]  迭代哈希表中的键值对





### Redis配置文件详解

- port：端口号，默认6379

- tcp-backlog

  ```bash
  设置tcp的backlog,backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列＋已经完成三次握手队列。
  在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。u
  注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值(128），所以需要确认增大/proc/sys/net/core/somaxconn和/proc/sys/net/ipv4/tcp_max_syn_backlog(128)两个值来达到想要的效果
  ```



### Redis新数据类型

#### Bitmaps

1. 简介

   ![image-20211101133201992](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133201992.png)

   

   2. 常用命令

      - setbit[key] [offset] [value] 设bitmaps中某个偏移量的值为0或1.offset：偏移量从0开始

        ![image-20211101133208197](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133208197.png)

        ```bash
        注意：很多应用的用户id以一个指定数字（例如10000 ）开头，直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费，通常的做法是每次做setbit 操作时将用户id减去这个指定数字。
        在第一次初始化 Bitmaps时，假如偏移量非常大，那么整个初始化过程执行会比较慢，可能会造成 Redis的阻塞。
        ```

      - getbit[key] [offset] 获取bitmaps中第偏移量为offset的值(offset从0开始)

      - bitcount[key] [start end]：统计字符串被设置为1的bit数，一般情况下给定的整个字符串都会被进行计数，通过指定额外的start和end参数可以让计数只在特定的位之间进行。start和end参数的设置都可以使用负数值，比如-1表示最后一个位，-2表示倒数第二个位。start、end是指bit组的字节的下标数，[start,end]左右皆为闭区间。[start,end]表示有(end-start+1)8个字节空间。例如[0,2]，即下标在0~(2-0+1)*8-1=23之间的下标中，值为1的个数。

      - bitop and(or/not/xor) [destkey] [key]：bitop是一个复合操作，它可以做多个Bitmaps的and(交集）、or(并集） 、not(非) 、 xor（异或）操作并将结果保存在destkey中。

   3. set与bitmap对比

      ![image-20211101133218544](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133218544.png)	![image-20211101133225425](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133225425.png)	![image-20211101133231200](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133231200.png)	

   

   
#### HyperLogLog

1. 简介
   
   ![image-20211101133250834](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133250834.png)	![image-20211101133304014](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133304014.png)	
   
   ![image-20211101133311498](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133311498.png)	
   
2. 常用命令
   
   - pfadd[key] [element]...：添加一个或多个元素到HyperLogLog中。执行命令后如果HLL估计的近似基数发生变化，则返回1，否则返回0
      - pfcount[key] [key]....：计算HLL的近似基数，可以计算多个
   - pfmerge[destkey] [sourcekey] [sourcekey]....：将一个或多个HLL合并后的结果存在另一个HLL destkey中。比如每月活跃用户可以使用每天的活跃用户来合并计算出来



#### Geospatial

1. 简介

   ![image-20211101133318417](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133318417.png)	

2. 基本命令

   - Geospatial底层是zset，所以可用zset的命令实现Geospatial自身命令不能实现的操作(如删除操作)

   - geoadd[key] [longitude] [latitude] [member] [longitude latitude member...]：添加地理位置(经度、纬度、名称)

     ```bash
     两极无法直接添加，一般会下载城市数据，直接通过Java程序一次性导入
     有效的经度从-180度到180度。有效的纬度从-85.05112878度到85.05112878度
     当坐标位置超出指定范围时，该命令将会返回一个错误
     已经添加的数据，是无法再次往里面添加的
     ```

   - geopos[key] [member...]：获取一个或多个指定地区的坐标值

   - geodis[key] [member1] [member2] [m|km|ft|mi]：获取两个位置之间的直线距离

     ```bash
     m表示单位为米(默认值)
     km表示单位为千米
     mi表示单位为英里
     ft表示单位为英尺
     ```

   - georadius[key] [longitude] [latitude] radius [m|km|ft|mi]：找出某一半径内的元素(经度 纬度 距离 单位)



### jedis访问redis步骤

- 关闭Linux防火墙或者开放redis的端口

  ```bash
  firewall-cmd --zone=public --add-port=6379/tcp --permanent开启6379防火墙
  firewall-cmd --reload：重新加载防火墙
  ```

- 记得注释掉配置文件中的bind 127.0.0.1

- redis.conf设置密码后，服务端启动时需带上redis.conf即指定配置文件启动

  ```bash
  ./redis-server redis.conf
  ```

- 客户端启动时需要使用-a带上requirpass的密码

  ```bash
  ./redis-cli -a 密码
  ```

- 使用jedis连接时，也需要加上密码

  ![image-20211101133324485](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133324485.png)





### redis事务

```bash
redis事务的本质就是一组命令的集合。一个事务中所有的命令都会被序列化(顺序)，按顺序执行
具有：一次性、顺序性、排他性
redis单条命令保证原子性(因为redis是单线程)，但事务不保证原子性
```



过程：

- 开启事务：multi

  ![image-20211101133330639](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133330639.png)

- 命令入队：输入一系列命令

  ![image-20211101133335437](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133335437.png)

- 中途也可取消事务：使用discard命令

  ![image-20211101133339820](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133339820.png)

- 执行事务：exec

  ![image-20211101133346972](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133346972.png)



#### 事务不执行的情况

> 出现编译型异常(代码有问题即命令本身有错误)，那么事务中的所有命令都不会执行

![image-20211101133427852](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133427852.png)	因为队列中有一次命令出现了语法错误，所以所有命令均未执行



> 出现运行时异常(如1/0这种)，出现此种错误，其他命令仍可正常执行

![image-20211101133435210](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133435210.png)

这种错误其他命令仍可正常执行

#### 乐观锁实现秒杀系统

```bash
我们知道大多数是基于数据版本（ version )的记录机制实现的。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个"version"字段来实现读取出数据时，将此版本号一同读出，之后更新时，对此版本号加1。此时，将提交数据的版本号与数据库表对应记录的当前版本号进行比对，如果提交的数据版本号大于数据库当前版本号，则予以更新，否则认为是过期数据。redis中可以使用watch命令会监视给定的key，当exec时候如果监视的key从调用watch后发生过变化，则整个事务会失败。也可以调用watch多次监视多个key。这样就可以对指定的key加乐观锁了。注意watch的key是对整个连接有效的，事务也一样。如果连接断开，监视和事务都会被自动清除。当然了exec , discard , unwatch命令都会清除连接中的所有监视
```

#### redis实现乐观锁

当一个线程在要对数据进行操作，但它的操作还未完成时，数据便被另一线程改变，这一线程操作的数据就不是原来的数据了。为了防止这种情况，可以使用乐观锁。

- 使用watch[key]....：监控一个或多个key，当事务未执行时，如果监控的key的值发生了改变，事务便不会执行

  - 先设定两个初值k1 k2，监控k1，然后进行事务

    ![image-20211101133447825](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133447825.png)

  - 在事务未执行时，在另一终端标签页对k1 k2进行修改

    ![image-20211101133453321](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133453321.png)	

  - 再回到原来的页面执行事务，发现事务并没有执行，使用unwatch后继续监控key

    ![image-20211101133459234](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133459234.png)

  

- 然后再使用unwatch命令解除监控，即可再次监控key



#### SpringBoot整合Redis

SpringBoot 2.x之后，原来使用的jedis被替换为了lettuce

- jedis:采用客户端直连，多个线程操作的话，是不安全的，如果想要避免不安全的，使用jedis pool连接池!BIO模式
- lettuce：采用netty，实例可以在多个线程中进程共享，不存在线程不安全的情况，可以减少线程数据。更像NIO模式



##### 编写redis配置类,对key value进行序列化(实体类需实现Serializable接口)

```java
/**
 * @author zdk
 * @date 2021/7/18 21:08
 */
@Configuration
public class RedisConfig {
    @Bean("myRedisTemplate")
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(redisConnectionFactory);
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer=new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper objectMapper=new ObjectMapper();
        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //key采用string的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //value采用Jackson序列化方式
        template.setValueSerializer(jackson2JsonRedisSerializer);
        //hash的key也采用string的序列化方式
        template.setHashKeySerializer(stringRedisSerializer);
        //value序列化方式采用Jackson
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        template.afterPropertiesSet();
        return template;
    }

    @Bean("myStringRedisTemplate")
    public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) {
        StringRedisTemplate template = new StringRedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();
        //key采用string的序列化方式
        template.setKeySerializer(stringRedisSerializer);
        //value采用string的序列化方式
        template.setValueSerializer(stringRedisSerializer);
        template.afterPropertiesSet();
        return template;
    }
}
```



##### 编写redis常用操作工具类

```java
/**
 * @author zdk
 * @date 2021/7/19 9:56
 */
@Component
public class RedisUtil {
    @Autowired
    @Qualifier("myRedisTemplate")
    private RedisTemplate<String, Object> redisTemplate;

    @Autowired
    @Qualifier("myStringRedisTemplate")
    private StringRedisTemplate stringRedisTemplate;

    // =============================common============================
    /**
     * 指定缓存失效时间
     * @param key 键
     * @param time 时间(秒)
     * @return
     */
    public Boolean expire(String key, long time) {
        try {
            if (time > 0) {
                redisTemplate.expire(key, time, TimeUnit.SECONDS);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 根据key 获取过期时间
     * @param key 键 不能为null
     * @return 时间(秒) 返回0代表为永久有效
     */
    public Long getExpire(String key) {
        return redisTemplate.getExpire(key, TimeUnit.SECONDS);
    }

    /**
     * 判断key是否存在
     * @param key 键
     * @return true 存在 false不存在
     */
    public Boolean hasKey(String key) {
        try {
            return redisTemplate.hasKey(key);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 删除缓存
     * @param key 可以传一个值 或多个
     */
    @SuppressWarnings("unchecked")
    public void del(String... key) {
        if (key != null && key.length > 0) {
            if (key.length == 1) {
                redisTemplate.delete(key[0]);
            } else {
                redisTemplate.delete((Collection<String>) CollectionUtils.arrayToList(key));
            }
        }
    }

    // ============================String=============================
    /**
     * 普通缓存获取
     * @param key 键
     * @return 值
     */
    public String get(String key) {
        return key == null ? null : stringRedisTemplate.opsForValue().get(key);
    }

    /**
     * 普通缓存放入
     * @param key 键
     * @param value 值
     * @return true成功 false失败
     */
    public boolean set(String key, String value) {
        try {
            stringRedisTemplate.opsForValue().set(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }


    /**
     * 普通缓存放入并设置时间
     * @param key 键
     * @param value 值
     * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期
     * @return true成功 false 失败
     */
    public boolean set(String key, String value, long time) {
        try {
            if (time > 0) {
                stringRedisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);
            } else {
                set(key, value);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 递增
     * @param key 键
     * @param delta 要增加几(大于0)
     * @return
     */
    public Long incr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递增因子必须大于0");
        }
        return stringRedisTemplate.opsForValue().increment(key, delta);
    }

    /**
     * 递减
     * @param key 键
     * @param delta 要减少几(小于0)
     * @return
     */
    public Long decr(String key, long delta) {
        if (delta < 0) {
            throw new RuntimeException("递减因子必须大于0");
        }
        return stringRedisTemplate.opsForValue().increment(key, -delta);
    }


    // ================================Map=================================
    /**
     * HashGet
     * @param key 键 不能为null
     * @param item 项 不能为null
     * @return 值
     */
    public Object hget(String key, String item) {
        return redisTemplate.opsForHash().get(key, item);
    }

    /**
     * 获取hashKey对应的所有键值
     * @param key 键
     * @return 对应的多个键值
     */
    public Map<Object, Object> hmget(String key) {
        return redisTemplate.opsForHash().entries(key);
    }

    /**
     * HashSet
     * @param key 键
     * @param map 对应多个键值
     * @return true 成功 false 失败
     */
    public boolean hmset(String key, Map<String, Object> map) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * HashSet 并设置时间
     * @param key 键
     * @param map 对应多个键值
     * @param time 时间(秒)
     * @return true成功 false失败
     */
    public boolean hmset(String key, Map<String, Object> map, long time) {
        try {
            redisTemplate.opsForHash().putAll(key, map);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 向一张hash表中放入数据,如果不存在将创建
     * @param key 键
     * @param item 项
     * @param value 值
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 向一张hash表中放入数据,如果不存在将创建
     * @param key 键
     * @param item 项
     * @param value 值
     * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间
     * @return true 成功 false失败
     */
    public boolean hset(String key, String item, Object value, long time) {
        try {
            redisTemplate.opsForHash().put(key, item, value);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 删除hash表中的值
     * @param key 键 不能为null
     * @param item 项 可以使多个 不能为null
     */
    public void hdel(String key, Object... item) {
        redisTemplate.opsForHash().delete(key, item);
    }

    /**
     * 判断hash表中是否有该项的值
     * @param key 键 不能为null
     * @param item 项 不能为null
     * @return true 存在 false不存在
     */
    public boolean hHasKey(String key, String item) {
        return redisTemplate.opsForHash().hasKey(key, item);
    }

    /**
     * hash递增 如果不存在,就会创建一个 并把新增后的值返回
     * @param key 键
     * @param item 项
     * @param by 要增加几(大于0)
     * @return
     */
    public double hincr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, by);
    }

    /**
     * hash递减
     * @param key 键
     * @param item 项
     * @param by 要减少记(小于0)
     * @return
     */
    public double hdecr(String key, String item, double by) {
        return redisTemplate.opsForHash().increment(key, item, -by);
    }

    // ============================set=============================
    /**
     * 根据key获取Set中的所有值
     * @param key 键
     * @return
     */
    public Set<Object> sGet(String key) {
        try {
            return redisTemplate.opsForSet().members(key);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 根据value从一个set中查询,是否存在
     * @param key 键
     * @param value 值
     * @return true 存在 false不存在
     */
    public Boolean sHasKey(String key, Object value) {
        try {
            return redisTemplate.opsForSet().isMember(key, value);
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将数据放入set缓存
     * @param key 键
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public Long sSet(String key, Object... values) {
        try {
            return redisTemplate.opsForSet().add(key, values);
        } catch (Exception e) {
            e.printStackTrace();
            return (long) 0;
        }
    }

    /**
     * 将set数据放入缓存
     * @param key 键
     * @param time 时间(秒)
     * @param values 值 可以是多个
     * @return 成功个数
     */
    public Long sSetAndTime(String key, long time, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().add(key, values);
            if (time > 0) {
                expire(key, time);
            }
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return (long)0;
        }
    }

    /**
     * 获取set缓存的长度
     * @param key 键
     * @return
     */
    public Long sGetSetSize(String key) {
        try {
            return redisTemplate.opsForSet().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return (long)0;
        }
    }

    /**
     * 移除值为value的
     * @param key 键
     * @param values 值 可以是多个
     * @return 移除的个数
     */
    public Long setRemove(String key, Object... values) {
        try {
            Long count = redisTemplate.opsForSet().remove(key, values);
            return count;
        } catch (Exception e) {
            e.printStackTrace();
            return (long)0;
        }
    }
    // ===============================list=================================

    /**
     * 获取list缓存的内容
     * @param key 键
     * @param start 开始
     * @param end 结束 0 到 -1代表所有值
     * @return
     */
    public List<Object> lGet(String key, long start, long end) {
        try {
            return redisTemplate.opsForList().range(key, start, end);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 获取list缓存的长度
     * @param key 键
     * @return
     */
    public Long lGetListSize(String key) {
        try {
            return redisTemplate.opsForList().size(key);
        } catch (Exception e) {
            e.printStackTrace();
            return (long)0;
        }
    }

    /**
     * 通过索引 获取list中的值
     * @param key 键
     * @param index 索引 index>=0时， 0 表头，1 第二个元素，依次类推；index<0时，-1，表尾，-2倒数第二个元素，依次类推
     * @return
     */
    public Object lGetIndex(String key, long index) {
        try {
            return redisTemplate.opsForList().index(key, index);
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @return
     */
    public boolean lSet(String key, Object value) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * @return
     */
    public boolean lSet(String key, Object value, long time) {
        try {
            redisTemplate.opsForList().rightPush(key, value);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     * @param key 键
     * @param value 值
     * @return
     */
    public boolean lSet(String key, List<Object> value) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 将list放入缓存
     *
     * @param key 键
     * @param value 值
     * @param time 时间(秒)
     * @return
     */
    public boolean lSet(String key, List<Object> value, long time) {
        try {
            redisTemplate.opsForList().rightPushAll(key, value);
            if (time > 0) {
                expire(key, time);
            }
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 根据索引修改list中的某条数据
     * @param key 键
     * @param index 索引
     * @param value 值
     * @return
     */
    public boolean lUpdateIndex(String key, long index, Object value) {
        try {
            redisTemplate.opsForList().set(key, index, value);
            return true;
        } catch (Exception e) {
            e.printStackTrace();
            return false;
        }
    }

    /**
     * 移除N个值为value
     * @param key 键
     * @param count 移除多少个
     * @param value 值
     * @return 移除的个数
     */
    public Long lRemove(String key, long count, Object value) {
        try {
            return redisTemplate.opsForList().remove(key, count, value);
        } catch (Exception e) {
            e.printStackTrace();
            return (long)0;
        }
    }

    // ===============================zset=================================


    public Boolean zAdd(String key,Object value,double score){
        try {
            return redisTemplate.opsForZSet().add(key, value, score);
        }catch (Exception e){
            e.printStackTrace();
            return false;
        }
    }

    public Set<Object> zRange(String key,long start,long stop){
        return redisTemplate.opsForZSet().range(key, start, stop);
    }

    public Set<Object> zRangeByScore(String key,double min,double max){
        return redisTemplate.opsForZSet().rangeByScore(key, min, max);
    }

    public Set<Object> zRangeAll(String key){
        return redisTemplate.opsForZSet().range(key, 0, -1);
    }

}

```

#### redis各种数据结构使用场景总结

1. String：value除了可以是字符串还能是数字
   - 计数器：incr
   - 统计多单位的数量
   - 粉丝数
   - 对象缓存存储
2. List：
   - 消息排队
   - 消息队列(Lpush,Rpop)
   - 栈(Lpush,Lpop)
3. Set：
   - 将每个用户关注的人放入一个set，粉丝放入一个set，可以使用sinter获取他们的共同关注
   - 共同爱好
4. hash
   - 更适合储存对象(易变更的数据)
5. zset
   - set排序
   - 储存班级成绩表、工资表排序
   - 消息排序，用权重判断是否重要
   - 排行榜应用实现，取TopN测试
6. Geospatial
   - 地理位置
   - 附近的人
7. bitmap
   - 网站、游戏签到
   - 网站每天访问人数统计
   - 指定用户是否在某一天访问了



#### redis持久化

1. RDB(Redis DataBase)

   ![image-20211101133513460](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133513460.png)	

   ```bash
   在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是Snapshot快照，它恢复时是将快照文件直接读到内存里。
   
   Redis会单独创建 ( fork )一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。
   
   整个过程中，主进程是不进行任何I0操作的。这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。
   ```

   ```bash
   RDB保存的文件是dump.rdb
   ```

   - 触发规则：

     1. save的规则满足的情况下，会自动触发rdb规则
     2. 执行flushall命令，也会触发rdb
     3. 退出redis服务，也会产生rdb文件

     备份就自动生成一个dump.rdb

   - 如何恢复数据：

     1. 只需将rdb文件放在redis启动目录下，redis会自动检查恢复dump.rdb中的数据

     2. 查看需要存在的位置

        ```bash
        127.0.0.1:6379> config get dir
        1) "dir"
        2) "/usr/local/redis/bin" #如果在此目录下存在dump.rdb文件，redis会自动恢复其中的数据
        ```

   优点：

   - 适合大规模的数据恢复
   - 适用于对数据完整性要求不高的情况

   缺点：

   - 需要一定的时间间隔进行操作。如果redis意外宕机，最后一次修改的数据就没了
   - fork进程的时候，会占用一定的内存

2. AOF(Append Only File)

   ```bash
   将所有写入的命令都记录下来，储存在文件中，恢复的时候就把文件中的命令全部执行一次。
   以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。
   ```

   ![image-20211101133519677](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133519677.png)	

   **AOF保存的是appendonly.aof文件**

   

   AOF在redis.conf中的配置

   ```bash
   appendonly no #默认是不开启的
   # The name of the append only file (default: "appendonly.aof")
   appendfilename "appendonly.aof" #保存的文件名
   ```

   ```bash
   #AOF持久化策略
   
   appendfsync always #每次修改都会执行一次sync，会消耗更多性能
   appendfsync everysec #每一秒执行一次sync，可能会丢失这一秒的数据
   appendfsync no #不执行sync，这时操作系统自己同步数据，速度最快
   ```

   ```bash
   #自动重写的规则
   no-appendfsync-on-rewrite no  #是否开启文件重写
   auto-aof-rewrite-percentage 100 #重写的精确值
   auto-aof-rewrite-min-size 64mb #重写的文件最小值，如果文件超过这个值，就会fork一个新的进程来将文件进行重写
   ```

   ```bash
   开启appendonly yes后重启redis即可生效，重启时如果没有appendonly.aof文件，会自动生成一个
   
   如果原来的aof文件有错误，此时redis是不能启动的。需要运行 redis-check-aof --fix appendonly.aof
   ```

   优点：

   - 每次修改都会同步，数据的完整性更好
   - 每秒同步一次，只可能会丢失一秒的数据
   - 从不同步的话，效率最高

   缺点：

   - aof文件远大于rdb，修复速度更慢
   - aof是io操作，运行效率也要比rdb慢，所以redis默认配置是rdb而不是aof

   扩展：

   1. RDB持久化方式能够在指定的时间间隔内对你的数据进行快照存储
   2. AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以Redis 协议追加保存每次写的操作到文件末尾，Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。
   3. **只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化**
   4. 同时开启两种持久化方式
      - 在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。
      - RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件，那要不要只使用AOF呢?作者建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份），快速重启，而且不会有AOF可能潜在的Bug，留着作为一个万一的手段。
   5. 性能建议
      - 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。
      - 如果Enable AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了，代价一是带来了持续的lO，二是AOFrewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上，默认超过原大小100%大小重写可以改到适当的数值。
      - 如果不Enable AOF，仅靠Master-Slave Repllcation实现高可用性也可以，能省掉一大笔IO，也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave 中的 RDB文件，载入较新的那个，微博就是这种架构。



### Redis的发布和订阅

#### 什么是发布和订阅

```bash
Redis发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息
Redis客户端可以订阅任意数量的频道
```



#### 发布订阅命令行实现(广发用于构建即时通信应用，如网络聊天室(chatroom)和实时广播、实时提醒等)

- PSUBSCRIBE pattern [pattern ...]：订阅一个或多个符合给定模式的频道
- PUBSUB subcommand [argument [argument ...]]：查看订阅和发布系统状态
- PUBLISH channel message：将消息发送到指定的频道
- PUNSUBSCRIBE [pattern [pattern ...]]：退订所有给定模式的频道
- SUBSCRIBE channel [channel...]：订阅给定的一个或多个频道的信息
- UNSUBSCRIBE [channel [channel...]]：退订给定的频道



1. 打开一个客户端订阅一个频道为channel1

   ```bash
   SUBSCRIBE channel1
   ```

   ![image-20211101133528305](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133528305.png)	

2. 打开另一个客户端，给channel1发布消息hello

   ```bash
   publish channel1 hello
   ```

   ![image-20211101133533705](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133533705.png)	

   发布成功返回的是订阅者的数量

3. 订阅了channel1的订阅者收到消息

   ![image-20211101133538886](https://gitee.com/hnistzdk/picture/raw/master/images/image-20211101133538886.png)	

   

   注：发布的消息没有持久化，没有订阅的客户端收不到hello，只能收到订阅后channel1发布的消息

发布订阅的原理：

```bash
	Redis是使用C实现的，通过分析Redis 源码里的pubsub.c文件，了解发布和订阅机制的底层实现，籍此加深对Redis的理解。Redis 通过PUBLISH、SUBSCRIBE和PSUBSCRIBE等命令实现发布和订阅功能。
	通过SUBSCRIBE命令订阅某频道后，redis-server里维护了一个字典，字典的键就是一个个channel，而字典的值则是一个链表，链表中保存了所有订阅这个channel的客户端。SUBSCRIBE命令的关键，就是将客户端添加到给定channel的订阅链表中。通过PUBLISH命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的channel字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。
	Pub/Sub从字面上理解就是发布( Publish )与订阅(Subscribe )，在Redis中，你可以设定对某一个key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。
```

**使用场景：**

- 实时消息系统(网站的消息推送)
- 实时聊天(频道当做聊天室，将信息回显给所有人)
- 订阅，关注系统

更复杂的场景就会使用消息中间件：MQ 等